wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: mattias421. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.3
wandb: Run data is saved locally in ./results/vanilla/wandb/run-20250116_152113-3rw0trgo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cfm_sigma10
wandb: ‚≠êÔ∏è View project at https://wandb.ai/mattias421/tdmolflow
wandb: üöÄ View run at https://wandb.ai/mattias421/tdmolflow/runs/3rw0trgo
using rdkit
parse_int_list 0,0,0,1,1,1,1,1,1
parse_int_list 1,1,1,1,1,1,1,1,1
seed:  1464903923
Creating output directory...
Loading dataset...
training.dataset.QM9Dataset () {'condition_on_alpha': False, 'atom_type_norm': 0.25, 'shuffle_node_ordering': True, 'only_second_half': False, 'remove_h': True, 'charge_norm': 10.0, 'train_or_valid': 'train', 'subset': -1, 'random_rotation': False, 'pos_norm': 1.0}
------- making QM9 dataset --------
Entropy of n_nodes: H[N] -2.475700616836548
Removing h
QM9 Dataset Length 100000
/fastdata/acq22mc/anaconda/.envs/tdmolflow/lib/python3.11/site-packages/torch/utils/data/sampler.py:65: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.
  warnings.warn("`data_source` argument is not used and will be removed in 2.2.0."
/fastdata/acq22mc/anaconda/.envs/tdmolflow/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
training.dataset.QM9Dataset () {'condition_on_alpha': False, 'atom_type_norm': 0.25, 'shuffle_node_ordering': True, 'only_second_half': False, 'remove_h': True, 'charge_norm': 10.0, 'train_or_valid': 'valid', 'subset': -1, 'random_rotation': False, 'pos_norm': 1.0}
------- making QM9 dataset --------
Entropy of n_nodes: H[N] -2.475700616836548
Removing h
QM9 Dataset Length 100000
Created structure with observedness [0 0 0 1 1 1 1 1 1]
Constructing network...
training.networks.EpsilonPrecond () {'model_type': 'EGNNMultiHeadJump', 'n_attn_blocks': 8, 'transformer_dim': 128, 'rate_use_x0_pred': True, 'n_heads': 8, 'detach_last_layer': True, 'noise_embed': 'ts*1000', 'use_fp16': False, 'augment_dim': 9, 'structure': <training.structure.Structure object at 0x2b7fffe67690>}
num parameters:  7327554
training.sampler.JumpSampler () {'no_noise_final_step': False, 'condition_sweep_idx': 0, 'dt': 0.001, 'sample_near_atom': True, 'corrector_finish_time': 0.003, 'condition_type': 'sweep', 'condition_sweep_path': None, 'dt_schedule_tc': 0.5, 'dt_schedule_l': 0.001, 'corrector_start_time': 0.1, 'corrector_snr': 0.1, 'dt_schedule_h': 0.05, 'do_conditioning': False, 'corrector_steps': 0, 'guidance_weight': 1.0, 'dt_schedule': 'uniform', 'do_jump_corrector': False, 'structure': <training.structure.Structure object at 0x2b7fffe67690>}
training.grad_conditioning.MoleculeJump () {'grad_norm_clip': 1.0, 'lr_rampup_kimg': 320}
Setting up optimizer...
training.loss.JumpLossFinalDim () {'loss_type': 'eps', 'x0_logit_ce_loss_weight': 1.0, 'score_loss_weight': 1.0, 'rate_loss_weight': 1.0, 'rate_function_name': 'step', 'vp_sde_beta_min': 0.1, 'nearest_atom_loss_weight': 1.0, 'nearest_atom_pred': True, 'mean_or_sum_over_dim': 'mean', 'rate_cut_t': 0.1, 'auto_loss_weight': 1.0, 'vp_sde_beta_max': 20.0, 'min_t': 0.001, 'noise_schedule_name': 'cfm_ode', 'structure': <training.structure.Structure object at 0x2b7fffe67690>}
torch.optim.Adam () {'params': <generator object Module.parameters at 0x2b800e403300>, 'lr': 3e-05, 'betas': [0.9, 0.999], 'eps': 1e-08}
Training for 200000 kimg...

Traceback (most recent call last):
  File "/mnt/fastdata/acq22mc/exp/tdmolflow/train.py", line 682, in <module>
    main()
  File "/fastdata/acq22mc/anaconda/.envs/tdmolflow/lib/python3.11/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/fastdata/acq22mc/anaconda/.envs/tdmolflow/lib/python3.11/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
         ^^^^^^^^^^^^^^^^
  File "/fastdata/acq22mc/anaconda/.envs/tdmolflow/lib/python3.11/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/fastdata/acq22mc/anaconda/.envs/tdmolflow/lib/python3.11/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/fastdata/acq22mc/exp/tdmolflow/train.py", line 676, in main
    training_loop.training_loop(**c)
  File "/mnt/fastdata/acq22mc/exp/tdmolflow/training/training_loop.py", line 259, in training_loop
    loss, loss_dict = loss_fn(net=ddp, st_batch=st_batch)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/fastdata/acq22mc/exp/tdmolflow/training/loss.py", line 114, in __call__
    st_batch.delete_dims(new_dims=dims_xt)
  File "/mnt/fastdata/acq22mc/exp/tdmolflow/training/structure.py", line 106, in delete_dims
    self.tuple_batch = self.gs.remove_problem_dims(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/fastdata/acq22mc/exp/tdmolflow/training/dataset/qm9.py", line 3538, in remove_problem_dims
    assert atom_type.shape == (B, *self.shapes_with_onehot()[1])
AssertionError
[1;34mwandb[0m: üöÄ View run [33mcfm_sigma10[0m at: [34mhttps://wandb.ai/mattias421/tdmolflow/runs/3rw0trgo[0m
