wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: mattias421. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.3
wandb: Run data is saved locally in ./results/vanilla/wandb/run-20241214_102435-8jyf7l67
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-terrain-35
wandb: ‚≠êÔ∏è View project at https://wandb.ai/mattias421/tdmolflow
wandb: üöÄ View run at https://wandb.ai/mattias421/tdmolflow/runs/8jyf7l67
using rdkit
parse_int_list 0,0,0,1,1,1,1,1,1
parse_int_list 1,1,1,1,1,1,1,1,1
seed:  2101140196
Creating output directory...
Loading dataset...
training.dataset.QM9Dataset () {'pos_norm': 1.0, 'remove_h': True, 'random_rotation': False, 'train_or_valid': 'train', 'atom_type_norm': 0.25, 'shuffle_node_ordering': True, 'subset': -1, 'charge_norm': 10.0, 'only_second_half': False, 'condition_on_alpha': False}
------- making QM9 dataset --------
Entropy of n_nodes: H[N] -2.475700616836548
Removing h
QM9 Dataset Length 100000
/fastdata/acq22mc/anaconda/.envs/tdmolflow/lib/python3.11/site-packages/torch/utils/data/sampler.py:65: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.
  warnings.warn("`data_source` argument is not used and will be removed in 2.2.0."
/fastdata/acq22mc/anaconda/.envs/tdmolflow/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
training.dataset.QM9Dataset () {'pos_norm': 1.0, 'remove_h': True, 'random_rotation': False, 'train_or_valid': 'valid', 'atom_type_norm': 0.25, 'shuffle_node_ordering': True, 'subset': -1, 'charge_norm': 10.0, 'only_second_half': False, 'condition_on_alpha': False}
------- making QM9 dataset --------
Entropy of n_nodes: H[N] -2.475700616836548
Removing h
QM9 Dataset Length 100000
Created structure with observedness [0 0 0 1 1 1 1 1 1]
Constructing network...
training.networks.EpsilonPrecond () {'model_type': 'EGNNMultiHeadJump', 'transformer_dim': 128, 'detach_last_layer': True, 'rate_use_x0_pred': True, 'n_heads': 8, 'n_attn_blocks': 8, 'noise_embed': 'ts*1000', 'use_fp16': False, 'augment_dim': 9, 'structure': <training.structure.Structure object at 0x2b7807ae7d90>}
num parameters:  7327554
training.sampler.JumpSampler () {'corrector_finish_time': 0.003, 'dt_schedule_tc': 0.5, 'guidance_weight': 1.0, 'corrector_start_time': 0.1, 'dt_schedule': 'uniform', 'condition_type': 'sweep', 'sample_near_atom': True, 'dt': 0.001, 'do_jump_corrector': False, 'corrector_snr': 0.1, 'dt_schedule_h': 0.05, 'corrector_steps': 0, 'no_noise_final_step': False, 'condition_sweep_path': None, 'dt_schedule_l': 0.001, 'condition_sweep_idx': 0, 'do_conditioning': False, 'structure': <training.structure.Structure object at 0x2b7807ae7d90>}
training.grad_conditioning.MoleculeJump () {'grad_norm_clip': 1.0, 'lr_rampup_kimg': 320}
Setting up optimizer...
training.loss.JumpLossFinalDim () {'score_loss_weight': 1.0, 'min_t': 0.001, 'auto_loss_weight': 1.0, 'vp_sde_beta_max': 20.0, 'nearest_atom_loss_weight': 1.0, 'mean_or_sum_over_dim': 'mean', 'vp_sde_beta_min': 0.01, 'x0_logit_ce_loss_weight': 1.0, 'rate_loss_weight': 1.0, 'loss_type': 'eps', 'noise_schedule_name': 'cfm_ode', 'nearest_atom_pred': True, 'rate_cut_t': 0.1, 'rate_function_name': 'step', 'structure': <training.structure.Structure object at 0x2b7807ae7d90>}
torch.optim.Adam () {'params': <generator object Module.parameters at 0x2b7814fdb680>, 'lr': 3e-05, 'betas': [0.9, 0.999], 'eps': 1e-08}
Training for 200000 kimg...

Traceback (most recent call last):
  File "/mnt/fastdata/acq22mc/exp/tdmolflow/train.py", line 682, in <module>
    main()
  File "/fastdata/acq22mc/anaconda/.envs/tdmolflow/lib/python3.11/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/fastdata/acq22mc/anaconda/.envs/tdmolflow/lib/python3.11/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
         ^^^^^^^^^^^^^^^^
  File "/fastdata/acq22mc/anaconda/.envs/tdmolflow/lib/python3.11/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/fastdata/acq22mc/anaconda/.envs/tdmolflow/lib/python3.11/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/fastdata/acq22mc/exp/tdmolflow/train.py", line 676, in main
    training_loop.training_loop(**c)
  File "/mnt/fastdata/acq22mc/exp/tdmolflow/training/training_loop.py", line 249, in training_loop
    dims, *data = next(dataset_iterator)
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/fastdata/acq22mc/anaconda/.envs/tdmolflow/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/fastdata/acq22mc/anaconda/.envs/tdmolflow/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1344, in _next_data
    return self._process_data(data)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/fastdata/acq22mc/anaconda/.envs/tdmolflow/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
    data.reraise()
  File "/fastdata/acq22mc/anaconda/.envs/tdmolflow/lib/python3.11/site-packages/torch/_utils.py", line 706, in reraise
    raise exception
AssertionError: Caught AssertionError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/fastdata/acq22mc/anaconda/.envs/tdmolflow/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/fastdata/acq22mc/anaconda/.envs/tdmolflow/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/fastdata/acq22mc/anaconda/.envs/tdmolflow/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/mnt/fastdata/acq22mc/exp/tdmolflow/training/dataset/qm9.py", line 3318, in __getitem__
    assert atom_types.shape == (
AssertionError

[1;34mwandb[0m: üöÄ View run [33mhopeful-terrain-35[0m at: [34mhttps://wandb.ai/mattias421/tdmolflow/runs/8jyf7l67[0m
